{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fc2e44-2121-4ff2-a2f5-1c36a4f69d8f",
   "metadata": {},
   "source": [
    "# WEED Inference\n",
    "This notebook demonstrates how we integrate Earth Observation (EO) data processing with ONNX-based machine learning (ML) inference within the WEED framework.\n",
    "\n",
    "Overview of the Process\n",
    "1) Loading Data Cube:\n",
    "We start by loading a data cube that contains all the enabled training features as individual bands. This lazy loading approach ensures efficient memory usage during data processing.\n",
    "\n",
    "2) Model Metadata Retrieval:\n",
    "The models are stored in an openEO-accessible storage site. Each model contains metadata specifying the features it was trained on.\n",
    "\n",
    "Important Note: Users must add this metadata to the stored models.\n",
    "The onnx_model_utilities module provides a utility function to extract metadata from a JSON file and embed it into the ONNX model. This approach is temporary and will be replaced as model training becomes fully integrated within the WEED framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8243ee19-d745-4958-97a4-6e67075953ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openeo\n",
    "\n",
    "from pathlib import Path\n",
    "from eo_processing.utils.helper import init_connection, getUDFpath\n",
    "from eo_processing.utils.onnx_model_utilities import get_name_output_cube_features\n",
    "\n",
    "from eo_processing.openeo.processing import generate_master_feature_cube\n",
    "from eo_processing.config import get_collection_options,  get_standard_processing_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b125488-ec56-4954-b44a-8dda843e7f12",
   "metadata": {},
   "source": [
    "## Step 1: Connect to openEO Processing Backend\n",
    "To begin, we establish a connection to the openEO backend. This connection is essential for accessing and processing EO data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33644bc-07e4-4733-841e-761b6772b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "backend = 'cdse' \n",
    "# establish the connection to the selected backend\n",
    "collection_options = {'S2_collection': 'SENTINEL2_L2A', 'S1_collection': 'SENTINEL1_GRD'}\n",
    "connection = openeo.connect(\"openeo-staging.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()\n",
    "# We call again the standard processing options for feature generation\n",
    "processing_options = get_standard_processing_options(provider=backend, task='feature_generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae12555-8963-4510-af03-73e89ecaae60",
   "metadata": {},
   "source": [
    "## Step 2: Specify Space and Time Context\n",
    "Define the spatial and temporal parameters for the data cube. This step ensures that only relevant data is loaded and processed during inference.\n",
    "\n",
    "Important note, the job options were seme-optimised in function of the input size. Larger extents, will have higher memory requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1c84a6-9aa2-4efc-aa49-fa59782731a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time context is given by start and end date\n",
    "start = '2021-01-01'\n",
    "end = '2022-01-01'   # the end is always exclusive\n",
    "AOI = {\n",
    "    'east': 4880000,\n",
    "    'south': 2896000,\n",
    "    'west': 4876000,\n",
    "    'north': 2900000,\n",
    "    'crs': 'EPSG:3035'\n",
    "}\n",
    "\n",
    "#note these job options were optimised for the spatiotemporal extent given above\n",
    "job_options = {'driver-memory': '1000m',\n",
    " 'driver-memoryOverhead': '1000m',\n",
    " 'executor-memory': '1500m',\n",
    " 'executor-memoryOverhead': '1500m',\n",
    " 'python-memory': '4000m',\n",
    " 'max-executors': 20,\n",
    " \"udf-dependency-archives\": [\n",
    "        \"https://s3.waw3-1.cloudferro.com/swift/v1/project_dependencies/onnx_dependencies_1.16.3.zip#onnx_deps\"\n",
    "        ]\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fabf8",
   "metadata": {},
   "source": [
    "## Step 3: Define the input cube\n",
    "\n",
    "Here we create the input datacube for the ML network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e5eb29-0bf2-4eab-9128-33786a011de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we link towards the used model\n",
    "\n",
    "#create the progress graph for the feature cube\n",
    "# define the S1/S2 processed feature cube (Note: do not set spatial extent since we had it over in the end)\n",
    "data_cube = generate_master_feature_cube(connection,\n",
    "                                            AOI,\n",
    "                                            start,\n",
    "                                            end,\n",
    "                                            **collection_options,\n",
    "                                            **processing_options)\n",
    "\n",
    "# load the DEM from a CDSE collection\n",
    "DEM = connection.load_collection(\n",
    "    \"COPERNICUS_30\",\n",
    "    bands=[\"DEM\"])\n",
    "# reduce the temporal domain since copernicus_30 collection is \"special\" and feature only are one time stamp\n",
    "DEM = DEM.reduce_dimension(dimension='t', reducer=lambda x: x.last(ignore_nodata=True))\n",
    "# resample the cube to 10m and EPSG of corresponding 20x20km grid tile\n",
    "DEM = DEM.resample_spatial(projection=processing_options['target_crs'],\n",
    "                            resolution=processing_options['resolution'],\n",
    "                            method=\"bilinear\").filter_bbox(AOI)\n",
    "# merge into the S1/S2 data cube\n",
    "data_cube = data_cube.merge_cubes(DEM)\n",
    "\n",
    "# load the WERN features from public STAC\n",
    "WENR = connection.load_stac(\"https://catalogue.weed.apex.esa.int/collections/wenr_features\")\n",
    "# resample the cube to 10m and EPSG of corresponding 20x20km grid tile\n",
    "WENR = WENR.resample_spatial(projection=processing_options['target_crs'],\n",
    "                                resolution=processing_options['resolution'],\n",
    "                                method=\"near\").filter_bbox(AOI)\n",
    "# drop the time dimension\n",
    "try:\n",
    "    WENR = WENR.drop_dimension('t')\n",
    "except:\n",
    "    # workaround if we still have the client issues with the time dimensions for STAC dataset with only one time stamp\n",
    "    WENR.metadata = WENR.metadata.add_dimension(\"t\", label=None, type=\"temporal\")\n",
    "    WENR = WENR.drop_dimension('t')\n",
    "\n",
    "# merge into the S1/S2 data cube\n",
    "data_cube = data_cube.merge_cubes(WENR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291ee68",
   "metadata": {},
   "source": [
    "## Step 4: Multimodel inference.\n",
    "\n",
    "Here we create and start an openeo job which performs the inference of all onnx models in the provided folder. \n",
    "\n",
    "As a next step we should eveluate wheter we prefer 1 logn running job over multiple parallel openEO jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52523c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'j-250508120220409fb9610ed8f0f4c475': send 'start'\n",
      "0:00:13 Job 'j-250508120220409fb9610ed8f0f4c475': created (progress 0%)\n",
      "0:00:18 Job 'j-250508120220409fb9610ed8f0f4c475': created (progress 0%)\n",
      "0:00:25 Job 'j-250508120220409fb9610ed8f0f4c475': created (progress 0%)\n",
      "0:00:33 Job 'j-250508120220409fb9610ed8f0f4c475': created (progress 0%)\n",
      "0:00:43 Job 'j-250508120220409fb9610ed8f0f4c475': created (progress 0%)\n",
      "0:00:56 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 8.2%)\n",
      "0:01:12 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 10.4%)\n",
      "0:01:33 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 12.9%)\n",
      "0:01:57 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 16.0%)\n",
      "0:02:27 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 19.4%)\n",
      "0:03:05 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 23.3%)\n",
      "0:03:52 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 27.6%)\n",
      "0:04:50 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 32.4%)\n",
      "0:05:51 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 36.7%)\n",
      "0:06:51 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 40.5%)\n",
      "0:07:51 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 43.9%)\n",
      "0:08:52 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 46.9%)\n",
      "0:09:52 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 49.6%)\n",
      "0:10:52 Job 'j-250508120220409fb9610ed8f0f4c475': running (progress 52.0%)\n",
      "0:11:53 Job 'j-250508120220409fb9610ed8f0f4c475': finished (progress 100%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "    if (!window.customElements || !window.customElements.get('openeo-job')) {\n",
       "        var el = document.createElement('script');\n",
       "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
       "        document.head.appendChild(el);\n",
       "\n",
       "        var font = document.createElement('font');\n",
       "        font.as = \"font\";\n",
       "        font.type = \"font/woff2\";\n",
       "        font.crossOrigin = true;\n",
       "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
       "        document.head.appendChild(font);\n",
       "    }\n",
       "    </script>\n",
       "    <openeo-job>\n",
       "        <script type=\"application/json\">{\"currency\": \"credits\", \"job\": {\"costs\": 12, \"created\": \"2025-05-08T12:02:20Z\", \"id\": \"j-250508120220409fb9610ed8f0f4c475\", \"process\": {\"process_graph\": {\"aggregatetemporalperiod1\": {\"arguments\": {\"data\": {\"from_node\": \"mask1\"}, \"period\": \"dekad\", \"reducer\": {\"process_graph\": {\"median1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"median\", \"result\": true}}}}, \"process_id\": \"aggregate_temporal_period\"}, \"aggregatetemporalperiod2\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial3\"}, \"period\": \"dekad\", \"reducer\": {\"process_graph\": {\"mean1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"mean\", \"result\": true}}}}, \"process_id\": \"aggregate_temporal_period\"}, \"apply1\": {\"arguments\": {\"data\": {\"from_node\": \"aggregatetemporalperiod1\"}, \"process\": {\"process_graph\": {\"linearscalerange1\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 0, \"outputMax\": 65534, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply2\": {\"arguments\": {\"data\": {\"from_node\": \"apply1\"}, \"process\": {\"process_graph\": {\"linearscalerange2\": {\"arguments\": {\"inputMax\": 10000, \"inputMin\": 0, \"outputMax\": 1, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply3\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension2\"}, \"process\": {\"process_graph\": {\"linearscalerange3\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 1, \"outputMax\": 65534, \"outputMin\": 1, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply4\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension6\"}, \"process\": {\"process_graph\": {\"linearscalerange4\": {\"arguments\": {\"inputMax\": 100, \"inputMin\": 0, \"outputMax\": 100, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"applydimension1\": {\"arguments\": {\"data\": {\"from_node\": \"apply2\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"add1\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add10\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"add\"}, \"add11\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add12\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"add\"}, \"add13\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement3\"}, \"y\": {\"from_node\": \"arrayelement6\"}}, \"process_id\": \"add\"}, \"add14\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement7\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add15\": {\"arguments\": {\"x\": 705, \"y\": {\"from_node\": \"multiply4\"}}, \"process_id\": \"add\"}, \"add2\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add3\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"add\"}, \"add4\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement1\"}}, \"process_id\": \"add\"}, \"add5\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add6\": {\"arguments\": {\"x\": {\"from_node\": \"add5\"}, \"y\": {\"from_node\": \"arrayelement6\"}}, \"process_id\": \"add\"}, \"add7\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"add\"}, \"add8\": {\"arguments\": {\"x\": {\"from_node\": \"add7\"}, \"y\": {\"from_node\": \"arrayelement6\"}}, \"process_id\": \"add\"}, \"add9\": {\"arguments\": {\"x\": {\"from_node\": \"divide7\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"add\"}, \"arrayelement1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 6}, \"process_id\": \"array_element\"}, \"arrayelement2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 2}, \"process_id\": \"array_element\"}, \"arrayelement3\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 3}, \"process_id\": \"array_element\"}, \"arrayelement4\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 8}, \"process_id\": \"array_element\"}, \"arrayelement5\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 1}, \"process_id\": \"array_element\"}, \"arrayelement6\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 9}, \"process_id\": \"array_element\"}, \"arrayelement7\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 5}, \"process_id\": \"array_element\"}, \"arrayelement8\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 4}, \"process_id\": \"array_element\"}, \"arraymodify1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 10, \"values\": [{\"from_node\": \"divide1\"}, {\"from_node\": \"power1\"}, {\"from_node\": \"subtract4\"}, {\"from_node\": \"multiply3\"}, {\"from_node\": \"divide4\"}, {\"from_node\": \"divide5\"}, {\"from_node\": \"divide8\"}, {\"from_node\": \"divide9\"}, {\"from_node\": \"subtract12\"}, {\"from_node\": \"divide12\"}, {\"from_node\": \"add15\"}, {\"from_node\": \"divide16\"}]}, \"process_id\": \"array_modify\", \"result\": true}, \"divide1\": {\"arguments\": {\"x\": {\"from_node\": \"subtract1\"}, \"y\": {\"from_node\": \"add1\"}}, \"process_id\": \"divide\"}, \"divide10\": {\"arguments\": {\"x\": {\"from_node\": \"subtract10\"}, \"y\": {\"from_node\": \"add11\"}}, \"process_id\": \"divide\"}, \"divide11\": {\"arguments\": {\"x\": {\"from_node\": \"subtract11\"}, \"y\": {\"from_node\": \"add12\"}}, \"process_id\": \"divide\"}, \"divide12\": {\"arguments\": {\"x\": {\"from_node\": \"subtract13\"}, \"y\": {\"from_node\": \"add13\"}}, \"process_id\": \"divide\"}, \"divide13\": {\"arguments\": {\"x\": {\"from_node\": \"add14\"}, \"y\": 2}, \"process_id\": \"divide\"}, \"divide14\": {\"arguments\": {\"x\": {\"from_node\": \"subtract14\"}, \"y\": {\"from_node\": \"subtract15\"}}, \"process_id\": \"divide\"}, \"divide15\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement3\"}, \"y\": {\"from_node\": \"arrayelement8\"}}, \"process_id\": \"divide\"}, \"divide16\": {\"arguments\": {\"x\": {\"from_node\": \"subtract16\"}, \"y\": {\"from_node\": \"divide15\"}}, \"process_id\": \"divide\"}, \"divide2\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement3\"}}, \"process_id\": \"divide\"}, \"divide3\": {\"arguments\": {\"x\": {\"from_node\": \"subtract5\"}, \"y\": {\"from_node\": \"add2\"}}, \"process_id\": \"divide\"}, \"divide4\": {\"arguments\": {\"x\": {\"from_node\": \"subtract6\"}, \"y\": {\"from_node\": \"add3\"}}, \"process_id\": \"divide\"}, \"divide5\": {\"arguments\": {\"x\": {\"from_node\": \"subtract7\"}, \"y\": {\"from_node\": \"add4\"}}, \"process_id\": \"divide\"}, \"divide6\": {\"arguments\": {\"x\": {\"from_node\": \"add6\"}, \"y\": 3}, \"process_id\": \"divide\"}, \"divide7\": {\"arguments\": {\"x\": {\"from_node\": \"add8\"}, \"y\": 3}, \"process_id\": \"divide\"}, \"divide8\": {\"arguments\": {\"x\": {\"from_node\": \"subtract8\"}, \"y\": {\"from_node\": \"add9\"}}, \"process_id\": \"divide\"}, \"divide9\": {\"arguments\": {\"x\": {\"from_node\": \"subtract9\"}, \"y\": {\"from_node\": \"add10\"}}, \"process_id\": \"divide\"}, \"multiply1\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"subtract2\"}}, \"process_id\": \"multiply\"}, \"multiply2\": {\"arguments\": {\"x\": {\"from_node\": \"multiply1\"}, \"y\": {\"from_node\": \"subtract3\"}}, \"process_id\": \"multiply\"}, \"multiply3\": {\"arguments\": {\"x\": {\"from_node\": \"divide3\"}, \"y\": {\"from_node\": \"arrayelement1\"}}, \"process_id\": \"multiply\"}, \"multiply4\": {\"arguments\": {\"x\": 35, \"y\": {\"from_node\": \"divide14\"}}, \"process_id\": \"multiply\"}, \"power1\": {\"arguments\": {\"base\": {\"from_node\": \"multiply2\"}, \"p\": 0.3333333333333333}, \"process_id\": \"power\"}, \"subtract1\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract10\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract11\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"subtract\"}, \"subtract12\": {\"arguments\": {\"x\": {\"from_node\": \"divide10\"}, \"y\": {\"from_node\": \"divide11\"}}, \"process_id\": \"subtract\"}, \"subtract13\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement3\"}, \"y\": {\"from_node\": \"arrayelement6\"}}, \"process_id\": \"subtract\"}, \"subtract14\": {\"arguments\": {\"x\": {\"from_node\": \"divide13\"}, \"y\": {\"from_node\": \"arrayelement3\"}}, \"process_id\": \"subtract\"}, \"subtract15\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement8\"}, \"y\": {\"from_node\": \"arrayelement3\"}}, \"process_id\": \"subtract\"}, \"subtract16\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement7\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract2\": {\"arguments\": {\"x\": 1, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract3\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract4\": {\"arguments\": {\"x\": {\"from_node\": \"divide2\"}, \"y\": 1}, \"process_id\": \"subtract\"}, \"subtract5\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"subtract\"}, \"subtract6\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement1\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"subtract\"}, \"subtract7\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement1\"}}, \"process_id\": \"subtract\"}, \"subtract8\": {\"arguments\": {\"x\": {\"from_node\": \"divide6\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"subtract\"}, \"subtract9\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement5\"}, \"y\": {\"from_node\": \"arrayelement4\"}}, \"process_id\": \"subtract\"}}}}, \"process_id\": \"apply_dimension\"}, \"applydimension2\": {\"arguments\": {\"data\": {\"from_node\": \"aggregatetemporalperiod2\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"add16\": {\"arguments\": {\"x\": {\"from_node\": \"multiply5\"}, \"y\": 83}, \"process_id\": \"add\"}, \"add17\": {\"arguments\": {\"x\": {\"from_node\": \"multiply6\"}, \"y\": 83}, \"process_id\": \"add\"}, \"arraycreate1\": {\"arguments\": {\"data\": [{\"from_node\": \"if1\"}, {\"from_node\": \"if2\"}]}, \"process_id\": \"array_create\", \"result\": true}, \"arrayelement10\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 0}, \"process_id\": \"array_element\"}, \"arrayelement11\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 1}, \"process_id\": \"array_element\"}, \"arrayelement12\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 1}, \"process_id\": \"array_element\"}, \"arrayelement9\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 0}, \"process_id\": \"array_element\"}, \"divide17\": {\"arguments\": {\"x\": {\"from_node\": \"add16\"}, \"y\": 20}, \"process_id\": \"divide\"}, \"divide18\": {\"arguments\": {\"x\": {\"from_node\": \"add17\"}, \"y\": 20}, \"process_id\": \"divide\"}, \"if1\": {\"arguments\": {\"accept\": 1, \"reject\": {\"from_node\": \"power2\"}, \"value\": {\"from_node\": \"isnodata1\"}}, \"process_id\": \"if\"}, \"if2\": {\"arguments\": {\"accept\": 1, \"reject\": {\"from_node\": \"power3\"}, \"value\": {\"from_node\": \"isnodata2\"}}, \"process_id\": \"if\"}, \"isnodata1\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement10\"}}, \"process_id\": \"is_nodata\"}, \"isnodata2\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement12\"}}, \"process_id\": \"is_nodata\"}, \"log1\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement9\"}}, \"process_id\": \"log\"}, \"log2\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement11\"}}, \"process_id\": \"log\"}, \"multiply5\": {\"arguments\": {\"x\": 10, \"y\": {\"from_node\": \"log1\"}}, \"process_id\": \"multiply\"}, \"multiply6\": {\"arguments\": {\"x\": 10, \"y\": {\"from_node\": \"log2\"}}, \"process_id\": \"multiply\"}, \"power2\": {\"arguments\": {\"base\": 10, \"p\": {\"from_node\": \"divide17\"}}, \"process_id\": \"power\"}, \"power3\": {\"arguments\": {\"base\": 10, \"p\": {\"from_node\": \"divide18\"}}, \"process_id\": \"power\"}}}}, \"process_id\": \"apply_dimension\"}, \"applydimension3\": {\"arguments\": {\"data\": {\"from_node\": \"apply3\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"arraycreate2\": {\"arguments\": {\"data\": [{\"from_node\": \"subtract17\"}, {\"from_node\": \"subtract18\"}]}, \"process_id\": \"array_create\", \"result\": true}, \"arrayelement13\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 0}, \"process_id\": \"array_element\"}, \"arrayelement14\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 1}, \"process_id\": \"array_element\"}, \"log3\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement13\"}}, \"process_id\": \"log\"}, \"log4\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement14\"}}, \"process_id\": \"log\"}, \"multiply7\": {\"arguments\": {\"x\": 20, \"y\": {\"from_node\": \"log3\"}}, \"process_id\": \"multiply\"}, \"multiply8\": {\"arguments\": {\"x\": 20, \"y\": {\"from_node\": \"log4\"}}, \"process_id\": \"multiply\"}, \"subtract17\": {\"arguments\": {\"x\": {\"from_node\": \"multiply7\"}, \"y\": 83}, \"process_id\": \"subtract\"}, \"subtract18\": {\"arguments\": {\"x\": {\"from_node\": \"multiply8\"}, \"y\": 83}, \"process_id\": \"subtract\"}}}}, \"process_id\": \"apply_dimension\"}, \"applydimension4\": {\"arguments\": {\"context\": {\"TileSize\": 128, \"parallel\": true}, \"data\": {\"from_node\": \"applydimension3\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"add18\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement15\"}, \"y\": {\"from_node\": \"arrayelement16\"}}, \"process_id\": \"add\"}, \"arraycreate3\": {\"arguments\": {\"data\": [{\"from_node\": \"arrayelement15\"}, {\"from_node\": \"arrayelement16\"}, {\"from_node\": \"divide19\"}, {\"from_node\": \"subtract19\"}, {\"from_node\": \"divide20\"}]}, \"process_id\": \"array_create\", \"result\": true}, \"arrayelement15\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"label\": \"VV\"}, \"process_id\": \"array_element\"}, \"arrayelement16\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"label\": \"VH\"}, \"process_id\": \"array_element\"}, \"divide19\": {\"arguments\": {\"x\": {\"from_node\": \"multiply9\"}, \"y\": {\"from_node\": \"add18\"}}, \"process_id\": \"divide\"}, \"divide20\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement16\"}, \"y\": {\"from_node\": \"arrayelement15\"}}, \"process_id\": \"divide\"}, \"multiply9\": {\"arguments\": {\"x\": 4, \"y\": {\"from_node\": \"arrayelement16\"}}, \"process_id\": \"multiply\"}, \"subtract19\": {\"arguments\": {\"x\": {\"from_node\": \"arrayelement16\"}, \"y\": {\"from_node\": \"arrayelement15\"}}, \"process_id\": \"subtract\"}}}}, \"process_id\": \"apply_dimension\"}, \"applydimension5\": {\"arguments\": {\"context\": {\"TileSize\": 128, \"parallel\": true}, \"data\": {\"from_node\": \"mergecubes1\"}, \"dimension\": \"t\", \"process\": {\"process_graph\": {\"arrayconcat1\": {\"arguments\": {\"array1\": {\"from_node\": \"quantiles1\"}, \"array2\": [{\"from_node\": \"mean2\"}, {\"from_node\": \"sd1\"}, {\"from_node\": \"sum1\"}, {\"from_node\": \"subtract20\"}]}, \"process_id\": \"array_concat\", \"result\": true}, \"mean2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"mean\"}, \"quantiles1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"probabilities\": [0.02, 0.25, 0.5, 0.75, 0.98]}, \"process_id\": \"quantiles\"}, \"quantiles2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"probabilities\": [0.75]}, \"process_id\": \"quantiles\"}, \"quantiles3\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"probabilities\": [0.25]}, \"process_id\": \"quantiles\"}, \"sd1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"sd\"}, \"subtract20\": {\"arguments\": {\"x\": {\"from_node\": \"quantiles2\"}, \"y\": {\"from_node\": \"quantiles3\"}}, \"process_id\": \"subtract\"}, \"sum1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"sum\"}}}, \"target_dimension\": \"bands\"}, \"process_id\": \"apply_dimension\"}, \"applydimension6\": {\"arguments\": {\"data\": {\"from_node\": \"mergecubes3\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"runudf1\": {\"arguments\": {\"context\": {\"model_id\": \"EUNIS2021plus_EU_v1_2024_PAN\"}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"import os\\nimport sys\\nimport functools\\nimport requests\\nimport tempfile\\nimport xarray as xr\\nimport numpy as np\\nimport json\\nimport shutil\\nfrom urllib.parse import urlparse\\nfrom openeo.udf import inspect\\nfrom openeo.metadata import CubeMetadata\\nfrom typing import Dict, List, Tuple, Union\\n\\nsys.path.append(\\\"onnx_deps\\\") \\nimport onnxruntime as ort\\n\\ndef apply_metadata(metadata: CubeMetadata, context: dict) -> CubeMetadata:\\n    model_id = context.get(\\\"model_id\\\")\\n    model_urls, output_band_names = get_model_metadata(model_id)\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=output_band_names)\\n   \\ndef get_model_metadata(modelID) -> Tuple[List[str], List[str]]:\\n    \\\"\\\"\\\"\\n    Fetches metadata for a given model ID from the WEED STAC API. The metadata includes\\n    the list of model URLs and the model's output band names. The search is crafted to\\n    ensure that only one model with the specified model ID is retrieved, as model IDs\\n    must be unique according to system rules. Raises an error in case of network issues,\\n    timeout, or if results are not unique.\\n\\n    :param modelID: The unique identifier of the model for which metadata is being\\n        requested.\\n    :return: A tuple containing a list of URLs for the model (`model_urls`) and a\\n        list of the model's output band names (`output_band_names`).\\n\\n    :raises RuntimeError: If a timeout occurs during communication with the API, if\\n        other network or request-related errors occur, or if the model ID is either\\n        not unique or not found in the system.\\n    \\\"\\\"\\\"\\n    # search endpoint of the WEED STAC API\\n    search_endpoint = \\\"https://catalogue.weed.apex.esa.int/search\\\"\\n    # create the search string\\n    search_payload = {\\n        \\\"limit\\\": 20,\\n        \\\"collections\\\": [\\\"model-STAC\\\"],\\n        \\\"filter\\\": {\\n            \\\"op\\\": \\\"=\\\",\\n            \\\"args\\\": [{\\\"property\\\": \\\"properties.modelID\\\" }, modelID]\\n        },\\n        \\\"filter-lang\\\": \\\"cql2-json\\\"\\n    }\\n    # execute the search\\n    try:\\n        r = requests.post(search_endpoint, json=search_payload, timeout=(3, 5))\\n    except requests.exceptions.Timeout:\\n        raise RuntimeError(\\\"Timeout while searching for model metadata.\\\")\\n    except requests.exceptions.RequestException as e:\\n        raise RuntimeError(f\\\"Error while searching for model metadata: {e}\\\")\\n\\n    # handle response - here we have the rule that modelIDs have to be UNIQUE\\n    if r.status_code == 200:\\n        search_results = r.json()\\n        if len(search_results[\\\"features\\\"]) > 1:\\n            raise RuntimeError(f\\\"Multiple models with modelID {modelID} found.\\\")\\n        elif len(search_results[\\\"features\\\"]) == 0:\\n            raise RuntimeError(f\\\"No model with modelID {modelID} found.\\\")\\n\\n        # extract needed metadata and check\\n        model_urls = search_results.get(\\\"features\\\",[])[0]['properties']['model_urls']\\n        output_band_names = search_results.get(\\\"features\\\",[])[0]['properties']['output_band_names']\\n        assert type(model_urls) is list, 'model_urls is not a list'\\n        assert type(output_band_names) is list, 'output_band_names is not a list'\\n        print(f\\\"Needed metadata for model {modelID} extracted.\\\")\\n    elif r.status_code == 400:\\n        print(\\\"Bad Request \\u2013 validation errors:\\\")\\n        raise RuntimeError(json.dumps(r.json(), indent=2))\\n    else:\\n        print(f\\\"Unexpected status {r.status_code}:\\\")\\n        raise RuntimeError(r.text)\\n    return model_urls, output_band_names\\n\\n\\ndef is_onnx_file(file_path: str) -> bool:\\n    \\\"\\\"\\\"\\n    Determines if a file is an ONNX file based on its extension.\\n\\n    This function checks the provided file path and determines whether the file\\n    is an ONNX file by checking if the file name ends with the `.onnx` file extension.\\n\\n    :param file_path: The path to the file whose extension is to be verified.\\n    :return: True if the file has a `.onnx` extension, otherwise False.\\n    \\\"\\\"\\\"\\n    return file_path.endswith('.onnx')\\n\\n\\ndef download_file(url: str, max_file_size_mb: int = 100, cache_dir: str = '/tmp/cache') -> str:\\n    \\\"\\\"\\\"\\n    Downloads a file from the specified URL. The file is\\n    cached in a given directory, and downloads of the same file are prevented using a locking\\n    mechanism. If the file already exists in the cache, it will not be downloaded again.\\n\\n    :param url: The URL of the file to download.\\n    :param max_file_size_mb: Maximum allowable file size in megabytes. Defaults to 100 MB.\\n    :param cache_dir: Directory where the downloaded file will be cached. Defaults to '/tmp/cache'.\\n    :return: The path to the downloaded file in the cache directory.\\n\\n    :raises ValueError: If the file size exceeds the maximum limit or if there is an issue during the\\n        download process.\\n    \\\"\\\"\\\"\\n    # Construct the file path within the cache directory (e.g., '/tmp/cache/model.onnx')\\n    os.makedirs(cache_dir, exist_ok=True)  # Ensure cache directory exists\\n\\n    file_name = os.path.basename(urlparse(url).path)\\n    file_path = os.path.join(cache_dir, file_name)\\n\\n    if os.path.exists(file_path):\\n        inspect(message=f\\\"File {file_path} already exists in cache.\\\")\\n        return file_path\\n\\n    try:\\n        response = requests.get(url, stream=True)\\n        response.raise_for_status()  # Raise error if the request fails\\n\\n        file_size = 0\\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\\\".onnx\\\") as temp_file:\\n            temp_file_path = temp_file.name\\n            for chunk in response.iter_content(chunk_size=1024):\\n                temp_file.write(chunk)\\n                file_size += len(chunk)\\n                if file_size > max_file_size_mb * 1024 * 1024:\\n                    raise ValueError(f\\\"Downloaded file exceeds the size limit of {max_file_size_mb} MB\\\")\\n\\n        shutil.move(temp_file_path, file_path)  # Move AFTER the `with` block, so the file isn't deleted\\n        return file_path\\n\\n    except Exception as e:\\n        if os.path.exists(temp_file_path):\\n            os.remove(temp_file_path)  # Cleanup if an error occurs\\n        raise ValueError(f\\\"Error downloading file: {e}\\\")\\n\\n\\n@functools.lru_cache(maxsize=1)\\ndef load_onnx_model(model_url: str, cache_dir: str = '/tmp/cache') -> Tuple[ort.InferenceSession, Dict[str, List[str]]]:\\n    \\\"\\\"\\\"\\n    Loads an ONNX model from a given URL, caches the model locally, and initializes an ONNX Runtime\\n    inference session. Additionally, extracts metadata such as input and output features from the model.\\n\\n    The function ensures the ONNX model is downloaded and locally stored in the specified cache directory\\n    to optimize repeated access. It also validates the model file and establishes an inference session with\\n    the CPU Execution Provider before safely extracting relevant metadata.\\n\\n    :param model_url: The URL pointing to the ONNX model to be downloaded and loaded. The URL must provide\\n                      a valid ONNX model file.\\n    :param cache_dir: An optional directory path to store the cached ONNX model. Defaults to '/tmp/cache',\\n                      ensuring local caching for repeated access.\\n    :return: A tuple where the first element is an initialized ONNX Runtime inference session, and the second\\n             element is a dictionary containing metadata extracted from the model. The metadata includes lists\\n             of input features and output features.\\n    :raises ValueError: If the ONNX model fails to load, initialize, or metadata extraction fails within the\\n                        processing steps.\\n    \\\"\\\"\\\"\\n    try:\\n        # Process the model file to ensure it's a valid ONNX model\\n        inspect(message=f\\\"downloading model file from {model_url}...\\\")\\n        model_path = download_file(model_url, cache_dir=cache_dir)\\n\\n        # Initialize the ONNX Runtime session\\n        inspect(message=f\\\"Initializing ONNX Runtime session for model at {model_path}...\\\")\\n        ort_session = ort.InferenceSession(model_path, providers=[\\\"CPUExecutionProvider\\\"])\\n\\n        # Extract metadata\\n        model_meta = ort_session.get_modelmeta()\\n\\n        input_features = model_meta.custom_metadata_map.get(\\\"input_features\\\", \\\"\\\")\\n        if input_features:\\n            if input_features.startswith('\\\"') and input_features.endswith('\\\"'):\\n                input_features = input_features[1:-1]\\n        input_features = [band.strip() for band in input_features.split(\\\",\\\")]\\n\\n        output_features = model_meta.custom_metadata_map.get(\\\"output_features\\\", \\\"\\\")\\n        if output_features:\\n            if output_features.startswith('\\\"') and output_features.endswith('\\\"'):\\n                output_features = output_features[1:-1]\\n        output_features = [band.strip() for band in output_features.split(\\\",\\\")]\\n\\n        metadata = {\\n            \\\"input_features\\\": input_features,\\n            \\\"output_features\\\": output_features,\\n        }\\n\\n        inspect(message=f\\\"Successfully extracted metadata from model at {model_path}...\\\")\\n        return ort_session, metadata\\n\\n    except Exception as e:\\n        raise ValueError(f\\\"Failed to load ONNX model from {model_url}: {e}\\\")\\n\\n\\n\\ndef preprocess_input(input_xr: xr.DataArray,\\n                     ort_session: ort.InferenceSession) -> Tuple[np.ndarray, Tuple[int, int, int]]:\\n    \\\"\\\"\\\"\\n    Preprocesses input data for model inference using an ONNX runtime session. This\\n    function takes an xarray DataArray, rearranges its dimensions, and reshapes its\\n    values to match the input requirements of the ONNX model specified by the given\\n    ONNX InferenceSession.\\n\\n    :param input_xr: Input data in the format of an xarray DataArray. The expected\\n        dimensions are \\\"y\\\", \\\"x\\\", and \\\"bands\\\", and the order of the dimensions will\\n        be transposed to match this requirement.\\n    :param ort_session: ONNX runtime inference session that specifies the model for\\n        inference. Used to determine the required input shape of the model.\\n    :return: A tuple containing:\\n        - A numpy array formatted to fit the input shape of the ONNX model.\\n        - The original shape of the input data as a tuple with the transposed \\\"y\\\",\\n          \\\"x\\\", and \\\"bands\\\" dimensions.\\n    \\\"\\\"\\\"\\n    input_xr = input_xr.transpose(\\\"y\\\", \\\"x\\\", \\\"bands\\\")\\n    input_shape = input_xr.shape\\n    input_np = input_xr.values.reshape(-1, ort_session.get_inputs()[0].shape[1])\\n    return input_np, input_shape\\n\\ndef run_inference(input_np: np.ndarray, ort_session: ort.InferenceSession) -> List[Dict[Union[str, int], float]]:\\n    \\\"\\\"\\\"\\n    Executes inference using an ONNX Runtime session and input numpy array. This function\\n    constructs the input data for the ONNX runtime, runs the session, and extracts the\\n    output probabilities as list of dictionaries.\\n\\n    :param input_np: Numpy array containing the input tensor data for the inference.\\n    :param ort_session: ONNX Runtime inference session object used to execute the model.\\n    :return: A list of dictionaries where each dictionary maps string labels to their\\n        corresponding probability values for each sample, as obtained from the model's output.\\n    \\\"\\\"\\\"\\n    ort_inputs = {ort_session.get_inputs()[0].name: input_np}\\n    ort_outputs = ort_session.run(None, ort_inputs)\\n    probabilities_dicts = ort_outputs[1]  # just take probability results\\n    return probabilities_dicts\\n\\ndef postprocess_output(probabilities_dicts: List[Dict[Union[str, int], float]],\\n                       input_shape: Tuple[int, int, int]) -> np.ndarray:\\n    \\\"\\\"\\\"\\n    Processes the output probabilities of a model into a reshaped and scaled NumPy array.\\n\\n    This function takes a list of dictionaries representing the probabilities for each\\n    class per sample, along with the input shape of the data. It then processes the\\n    probabilities into a 3D array where each band represents the scaled class probabilities,\\n    reshaped based on the given input shape. The resulting array is scaled to percentages\\n    (0-100) and converted to byte format.\\n\\n    :param probabilities_dicts: A list where each dictionary contains probabilities\\n        for each class, with class labels as keys and their corresponding probabilities as values.\\n    :param input_shape: A tuple representing the input shape in the form (height, width, bands).\\n    :return: A 3D NumPy array of shape (bands, height, width) containing scaled\\n        probabilities for each class in byte format.\\n    \\\"\\\"\\\"\\n\\n    # get the class labels assuming they are the same across all dictionaries (probabilities)\\n    class_labels = list(probabilities_dicts[0].keys())\\n\\n    # Convert probabilities from dicts for each sample into a 2D array with shape (n_samples, n_classes)\\n    probabilities = np.array([[prob[class_id] for class_id in class_labels] for prob in probabilities_dicts])\\n\\n    # Reshape probabilities into (bands, y, x), scale and convert to Byte\\n    probabilities = probabilities.T.reshape(len(class_labels), input_shape[0], input_shape[1]) * 100  # Scale by 100\\n    probabilities = probabilities.astype('uint8')\\n\\n    return probabilities\\n\\ndef create_output_xarray(probabilities: np.ndarray,\\n                         input_xr: xr.DataArray, output_bands) -> xr.DataArray:\\n    \\\"\\\"\\\"\\n    Generate an xarray.DataArray output based on the input probabilistic numpy array and the\\n    coordinate information from the input xarray.DataArray. This function takes the probability\\n    data and organizes it into a structured DataArray format with dimensions and corresponding\\n    coordinates inherited from the reference input.\\n\\n    :param probabilities: A 3D numpy array containing probability values structured in\\n        [bands, y, x] format. Represents the generated probabilities for input data.\\n    :param input_xr: The input reference xarray.DataArray. Used to inherit x and y coordinate\\n        information and ensure the output DataArray retains the input spatial alignment.\\n    :return: A 3D xarray.DataArray, structured with the given probabilities, and\\n        dimensions [bands, y, x]. Its coordinates for y and x are derived from the input_xr.\\n    \\\"\\\"\\\"\\n    return xr.DataArray(\\n        probabilities,\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": output_bands,\\n            'y': input_xr.coords['y'],\\n            'x': input_xr.coords['x']\\n            },\\n    )\\n\\ndef apply_datacube(cube: xr.DataArray, context: Dict) -> xr.DataArray:\\n    \\\"\\\"\\\"\\n    Applies multiple ONNX models on a given data cube for inference. The function ensures that the input\\n    cube is processed to fill any missing values and is in the correct data type to be compatible with the\\n    models. Models are loaded from the specified context, and their corresponding metadata is utilized to\\n    select appropriate sub-bands from the cube. Each model is applied sequentially, and the results are\\n    assembled into an output cube with all processed band outputs.\\n\\n    Note: The function name and arguments are defined by the UDF API.\\n    More information can be found here:\\n    https://open-eo.github.io/openeo-python-client/udf.html#udf-function-names-and-signatures\\n\\n    :param cube: The data cube on which the models will be applied. It must be an `xr.DataArray`.\\n    :param context: A dictionary that includes inference configuration, notably the list of models under\\n        \\\"model_list\\\" key.\\n    :return: An `xr.DataArray` representing the processed output cube after successfully applying all models.\\n    \\\"\\\"\\\"\\n    # fill nan in cube and make sure cube is in right dtype for inference\\n    cube = cube.fillna(0)\\n    cube = cube.astype('float32')\\n\\n    # get the list of models to apply on the cube from context\\n    model_id = context.get(\\\"model_id\\\")\\n    inspect(message=f\\\"running inference for: {model_id}\\\")\\n\\n    model_urls, output_band_names = get_model_metadata(model_id)\\n    \\n    # loop over the models and apply on input array\\n    output_cube_initialized = False\\n    for i, url in enumerate(model_urls):\\n\\n        inspect(message=f\\\"running inference for: {url}\\\")\\n\\n        # load the ONNX model and extract metadata\\n        ort_session, metadata = load_onnx_model(url, cache_dir=\\\"/tmp/cache\\\")\\n        input_band = metadata['input_features']\\n        output_band = metadata['output_features']\\n\\n        # Subset the data array using the selected indices\\n        inspect(message=f\\\"Subsetting the feature datacube by needed input features.\\\")\\n        subsampled_data_array = cube.sel(bands=input_band)\\n\\n        # preprocess input array to numpy array in correct shape\\n        input_np, input_shape = preprocess_input(subsampled_data_array, ort_session)\\n        # run inference\\n        inspect(message=f\\\"Running inference ...\\\")\\n        probabilities_dicts = run_inference(input_np, ort_session)\\n        # post-process probabilities to correct shape and Byte dtype\\n        inspect(message=f\\\"Post-processing probabilities and converting to xarray DataArray...\\\")\\n        probabilities = postprocess_output(probabilities_dicts, input_shape)\\n        # convert back to Xarray DataArray\\n        model_output_cube = create_output_xarray(probabilities, subsampled_data_array, output_band)\\n\\n        # merge the model results into one super-cube\\n        if not output_cube_initialized:\\n            # Initialize the output_cube only on the first iteration\\n            output_cube = model_output_cube\\n            output_cube_initialized = True\\n        else:\\n            # Append to output_cube starting from the second iteration\\n            output_cube = xr.concat([output_cube, model_output_cube], dim=\\\"bands\\\")\\n    # make sure output Xarray has the correct dtype\\n    output_cube = output_cube.astype('uint8')\\n\\n    return output_cube\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}}, \"process_id\": \"apply_dimension\"}, \"dropdimension1\": {\"arguments\": {\"data\": {\"from_node\": \"filterbbox2\"}, \"name\": \"t\"}, \"process_id\": \"drop_dimension\"}, \"filterbands1\": {\"arguments\": {\"bands\": [\"B02_p2\", \"B02_p25\", \"B02_median\", \"B02_p75\", \"B02_p98\", \"B02_mean\", \"B02_sd\", \"B02_sum\", \"B02_iqr\", \"B03_p2\", \"B03_p25\", \"B03_median\", \"B03_p75\", \"B03_p98\", \"B03_mean\", \"B03_sd\", \"B03_sum\", \"B03_iqr\", \"B04_p2\", \"B04_p25\", \"B04_median\", \"B04_p75\", \"B04_p98\", \"B04_mean\", \"B04_sd\", \"B04_sum\", \"B04_iqr\", \"B05_p2\", \"B05_p25\", \"B05_median\", \"B05_p75\", \"B05_p98\", \"B05_mean\", \"B05_sd\", \"B05_sum\", \"B05_iqr\", \"B06_p2\", \"B06_p25\", \"B06_median\", \"B06_p75\", \"B06_p98\", \"B06_mean\", \"B06_sd\", \"B06_sum\", \"B06_iqr\", \"B07_p2\", \"B07_p25\", \"B07_median\", \"B07_p75\", \"B07_p98\", \"B07_mean\", \"B07_sd\", \"B07_sum\", \"B07_iqr\", \"B08_p2\", \"B08_p25\", \"B08_median\", \"B08_p75\", \"B08_p98\", \"B08_mean\", \"B08_sd\", \"B08_sum\", \"B08_iqr\", \"B8A_p2\", \"B8A_p25\", \"B8A_median\", \"B8A_p75\", \"B8A_p98\", \"B8A_mean\", \"B8A_sd\", \"B8A_sum\", \"B8A_iqr\", \"B11_p2\", \"B11_p25\", \"B11_median\", \"B11_p75\", \"B11_p98\", \"B11_mean\", \"B11_sd\", \"B11_sum\", \"B11_iqr\", \"B12_p2\", \"B12_p25\", \"B12_median\", \"B12_p75\", \"B12_p98\", \"B12_mean\", \"B12_sd\", \"B12_sum\", \"B12_iqr\", \"NDVI_p2\", \"NDVI_p25\", \"NDVI_median\", \"NDVI_p75\", \"NDVI_p98\", \"NDVI_mean\", \"NDVI_sd\", \"NDVI_sum\", \"NDVI_iqr\", \"AVI_p2\", \"AVI_p25\", \"AVI_median\", \"AVI_p75\", \"AVI_p98\", \"AVI_mean\", \"AVI_sd\", \"AVI_sum\", \"AVI_iqr\", \"CIRE_p2\", \"CIRE_p25\", \"CIRE_median\", \"CIRE_p75\", \"CIRE_p98\", \"CIRE_mean\", \"CIRE_sd\", \"CIRE_sum\", \"CIRE_iqr\", \"NIRv_p2\", \"NIRv_p25\", \"NIRv_median\", \"NIRv_p75\", \"NIRv_p98\", \"NIRv_mean\", \"NIRv_sd\", \"NIRv_sum\", \"NIRv_iqr\", \"NDMI_p2\", \"NDMI_p25\", \"NDMI_median\", \"NDMI_p75\", \"NDMI_p98\", \"NDMI_mean\", \"NDMI_sd\", \"NDMI_sum\", \"NDMI_iqr\", \"NDWI_p2\", \"NDWI_p25\", \"NDWI_median\", \"NDWI_p75\", \"NDWI_p98\", \"NDWI_mean\", \"NDWI_sd\", \"NDWI_sum\", \"NDWI_iqr\", \"BLFEI_p2\", \"BLFEI_p25\", \"BLFEI_median\", \"BLFEI_p75\", \"BLFEI_p98\", \"BLFEI_mean\", \"BLFEI_sd\", \"BLFEI_sum\", \"BLFEI_iqr\", \"MNDWI_p2\", \"MNDWI_p25\", \"MNDWI_median\", \"MNDWI_p75\", \"MNDWI_p98\", \"MNDWI_mean\", \"MNDWI_sd\", \"MNDWI_sum\", \"MNDWI_iqr\", \"NDVIMNDWI_p2\", \"NDVIMNDWI_p25\", \"NDVIMNDWI_median\", \"NDVIMNDWI_p75\", \"NDVIMNDWI_p98\", \"NDVIMNDWI_mean\", \"NDVIMNDWI_sd\", \"NDVIMNDWI_sum\", \"NDVIMNDWI_iqr\", \"S2WI_p2\", \"S2WI_p25\", \"S2WI_median\", \"S2WI_p75\", \"S2WI_p98\", \"S2WI_mean\", \"S2WI_sd\", \"S2WI_sum\", \"S2WI_iqr\", \"S2REP_p2\", \"S2REP_p25\", \"S2REP_median\", \"S2REP_p75\", \"S2REP_p98\", \"S2REP_mean\", \"IRECI_p2\", \"IRECI_p25\", \"IRECI_median\", \"IRECI_p75\", \"IRECI_p98\", \"IRECI_mean\", \"IRECI_sd\", \"IRECI_sum\", \"IRECI_iqr\", \"VV_p2\", \"VV_p25\", \"VV_median\", \"VV_p75\", \"VV_p98\", \"VV_mean\", \"VV_sd\", \"VV_iqr\", \"VH_p2\", \"VH_p25\", \"VH_median\", \"VH_p75\", \"VH_p98\", \"VH_mean\", \"VH_sd\", \"VH_iqr\", \"RVI_p2\", \"RVI_p25\", \"RVI_median\", \"RVI_p75\", \"RVI_p98\", \"RVI_mean\", \"RVI_sd\", \"RVI_sum\", \"RVI_iqr\", \"VHVVD_p2\", \"VHVVD_p25\", \"VHVVD_median\", \"VHVVD_p75\", \"VHVVD_p98\", \"VHVVD_mean\", \"VHVVD_sd\", \"VHVVD_iqr\", \"VHVVR_p2\", \"VHVVR_p25\", \"VHVVR_median\", \"VHVVR_p75\", \"VHVVR_p98\", \"VHVVR_mean\", \"VHVVR_sd\", \"VHVVR_sum\", \"VHVVR_iqr\"], \"data\": {\"from_node\": \"renamelabels4\"}}, \"process_id\": \"filter_bands\"}, \"filterbbox1\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial4\"}, \"extent\": {\"crs\": \"EPSG:3035\", \"east\": 4880000, \"north\": 2900000, \"south\": 2896000, \"west\": 4876000}}, \"process_id\": \"filter_bbox\"}, \"filterbbox2\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial5\"}, \"extent\": {\"crs\": \"EPSG:3035\", \"east\": 4880000, \"north\": 2900000, \"south\": 2896000, \"west\": 4876000}}, \"process_id\": \"filter_bbox\"}, \"loadcollection1\": {\"arguments\": {\"bands\": [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"], \"id\": \"SENTINEL2_L2A\", \"properties\": {\"eo:cloud_cover\": {\"process_graph\": {\"lte1\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": 95}, \"process_id\": \"lte\", \"result\": true}}}}, \"spatial_extent\": {\"crs\": \"EPSG:3035\", \"east\": 4880000, \"north\": 2900000, \"south\": 2896000, \"west\": 4876000}, \"temporal_extent\": [\"2021-01-01\", \"2022-01-01\"]}, \"process_id\": \"load_collection\"}, \"loadcollection2\": {\"arguments\": {\"bands\": [\"SCL\"], \"id\": \"SENTINEL2_L2A\", \"properties\": {\"eo:cloud_cover\": {\"process_graph\": {\"lte2\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": 95}, \"process_id\": \"lte\", \"result\": true}}}}, \"spatial_extent\": {\"crs\": \"EPSG:3035\", \"east\": 4880000, \"north\": 2900000, \"south\": 2896000, \"west\": 4876000}, \"temporal_extent\": [\"2021-01-01\", \"2022-01-01\"]}, \"process_id\": \"load_collection\"}, \"loadcollection3\": {\"arguments\": {\"bands\": [\"VH\", \"VV\"], \"id\": \"SENTINEL1_GRD\", \"properties\": {\"polarisation\": {\"process_graph\": {\"eq2\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": \"VV&VH\"}, \"process_id\": \"eq\", \"result\": true}}}, \"sat:orbit_state\": {\"process_graph\": {\"eq1\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": \"DESCENDING\"}, \"process_id\": \"eq\", \"result\": true}}}}, \"spatial_extent\": {\"crs\": \"EPSG:3035\", \"east\": 4880000, \"north\": 2900000, \"south\": 2896000, \"west\": 4876000}, \"temporal_extent\": [\"2021-01-01\", \"2022-01-01\"]}, \"process_id\": \"load_collection\"}, \"loadcollection4\": {\"arguments\": {\"bands\": [\"DEM\"], \"id\": \"COPERNICUS_30\", \"spatial_extent\": null, \"temporal_extent\": null}, \"process_id\": \"load_collection\"}, \"loadstac1\": {\"arguments\": {\"url\": \"https://catalogue.weed.apex.esa.int/collections/wenr_features\"}, \"process_id\": \"load_stac\"}, \"mask1\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial1\"}, \"mask\": {\"from_node\": \"renamelabels1\"}}, \"process_id\": \"mask\"}, \"mergecubes1\": {\"arguments\": {\"cube1\": {\"from_node\": \"renamelabels2\"}, \"cube2\": {\"from_node\": \"renamelabels3\"}}, \"process_id\": \"merge_cubes\"}, \"mergecubes2\": {\"arguments\": {\"cube1\": {\"from_node\": \"filterbands1\"}, \"cube2\": {\"from_node\": \"filterbbox1\"}}, \"process_id\": \"merge_cubes\"}, \"mergecubes3\": {\"arguments\": {\"cube1\": {\"from_node\": \"mergecubes2\"}, \"cube2\": {\"from_node\": \"dropdimension1\"}}, \"process_id\": \"merge_cubes\"}, \"reducedimension1\": {\"arguments\": {\"data\": {\"from_node\": \"loadcollection4\"}, \"dimension\": \"t\", \"reducer\": {\"process_graph\": {\"last1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"ignore_nodata\": true}, \"process_id\": \"last\", \"result\": true}}}}, \"process_id\": \"reduce_dimension\"}, \"renamelabels1\": {\"arguments\": {\"data\": {\"from_node\": \"toscldilationmask1\"}, \"dimension\": \"bands\", \"target\": [\"S2-L2A-SCL_DILATED_MASK\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels2\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension1\"}, \"dimension\": \"bands\", \"target\": [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\", \"NDVI\", \"AVI\", \"CIRE\", \"NIRv\", \"NDMI\", \"NDWI\", \"BLFEI\", \"MNDWI\", \"NDVIMNDWI\", \"S2WI\", \"S2REP\", \"IRECI\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels3\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension4\"}, \"dimension\": \"bands\", \"target\": [\"VV\", \"VH\", \"RVI\", \"VHVVD\", \"VHVVR\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels4\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension5\"}, \"dimension\": \"bands\", \"target\": [\"B02_p2\", \"B02_p25\", \"B02_median\", \"B02_p75\", \"B02_p98\", \"B02_mean\", \"B02_sd\", \"B02_sum\", \"B02_iqr\", \"B03_p2\", \"B03_p25\", \"B03_median\", \"B03_p75\", \"B03_p98\", \"B03_mean\", \"B03_sd\", \"B03_sum\", \"B03_iqr\", \"B04_p2\", \"B04_p25\", \"B04_median\", \"B04_p75\", \"B04_p98\", \"B04_mean\", \"B04_sd\", \"B04_sum\", \"B04_iqr\", \"B05_p2\", \"B05_p25\", \"B05_median\", \"B05_p75\", \"B05_p98\", \"B05_mean\", \"B05_sd\", \"B05_sum\", \"B05_iqr\", \"B06_p2\", \"B06_p25\", \"B06_median\", \"B06_p75\", \"B06_p98\", \"B06_mean\", \"B06_sd\", \"B06_sum\", \"B06_iqr\", \"B07_p2\", \"B07_p25\", \"B07_median\", \"B07_p75\", \"B07_p98\", \"B07_mean\", \"B07_sd\", \"B07_sum\", \"B07_iqr\", \"B08_p2\", \"B08_p25\", \"B08_median\", \"B08_p75\", \"B08_p98\", \"B08_mean\", \"B08_sd\", \"B08_sum\", \"B08_iqr\", \"B8A_p2\", \"B8A_p25\", \"B8A_median\", \"B8A_p75\", \"B8A_p98\", \"B8A_mean\", \"B8A_sd\", \"B8A_sum\", \"B8A_iqr\", \"B11_p2\", \"B11_p25\", \"B11_median\", \"B11_p75\", \"B11_p98\", \"B11_mean\", \"B11_sd\", \"B11_sum\", \"B11_iqr\", \"B12_p2\", \"B12_p25\", \"B12_median\", \"B12_p75\", \"B12_p98\", \"B12_mean\", \"B12_sd\", \"B12_sum\", \"B12_iqr\", \"NDVI_p2\", \"NDVI_p25\", \"NDVI_median\", \"NDVI_p75\", \"NDVI_p98\", \"NDVI_mean\", \"NDVI_sd\", \"NDVI_sum\", \"NDVI_iqr\", \"AVI_p2\", \"AVI_p25\", \"AVI_median\", \"AVI_p75\", \"AVI_p98\", \"AVI_mean\", \"AVI_sd\", \"AVI_sum\", \"AVI_iqr\", \"CIRE_p2\", \"CIRE_p25\", \"CIRE_median\", \"CIRE_p75\", \"CIRE_p98\", \"CIRE_mean\", \"CIRE_sd\", \"CIRE_sum\", \"CIRE_iqr\", \"NIRv_p2\", \"NIRv_p25\", \"NIRv_median\", \"NIRv_p75\", \"NIRv_p98\", \"NIRv_mean\", \"NIRv_sd\", \"NIRv_sum\", \"NIRv_iqr\", \"NDMI_p2\", \"NDMI_p25\", \"NDMI_median\", \"NDMI_p75\", \"NDMI_p98\", \"NDMI_mean\", \"NDMI_sd\", \"NDMI_sum\", \"NDMI_iqr\", \"NDWI_p2\", \"NDWI_p25\", \"NDWI_median\", \"NDWI_p75\", \"NDWI_p98\", \"NDWI_mean\", \"NDWI_sd\", \"NDWI_sum\", \"NDWI_iqr\", \"BLFEI_p2\", \"BLFEI_p25\", \"BLFEI_median\", \"BLFEI_p75\", \"BLFEI_p98\", \"BLFEI_mean\", \"BLFEI_sd\", \"BLFEI_sum\", \"BLFEI_iqr\", \"MNDWI_p2\", \"MNDWI_p25\", \"MNDWI_median\", \"MNDWI_p75\", \"MNDWI_p98\", \"MNDWI_mean\", \"MNDWI_sd\", \"MNDWI_sum\", \"MNDWI_iqr\", \"NDVIMNDWI_p2\", \"NDVIMNDWI_p25\", \"NDVIMNDWI_median\", \"NDVIMNDWI_p75\", \"NDVIMNDWI_p98\", \"NDVIMNDWI_mean\", \"NDVIMNDWI_sd\", \"NDVIMNDWI_sum\", \"NDVIMNDWI_iqr\", \"S2WI_p2\", \"S2WI_p25\", \"S2WI_median\", \"S2WI_p75\", \"S2WI_p98\", \"S2WI_mean\", \"S2WI_sd\", \"S2WI_sum\", \"S2WI_iqr\", \"S2REP_p2\", \"S2REP_p25\", \"S2REP_median\", \"S2REP_p75\", \"S2REP_p98\", \"S2REP_mean\", \"S2REP_sd\", \"S2REP_sum\", \"S2REP_iqr\", \"IRECI_p2\", \"IRECI_p25\", \"IRECI_median\", \"IRECI_p75\", \"IRECI_p98\", \"IRECI_mean\", \"IRECI_sd\", \"IRECI_sum\", \"IRECI_iqr\", \"VV_p2\", \"VV_p25\", \"VV_median\", \"VV_p75\", \"VV_p98\", \"VV_mean\", \"VV_sd\", \"VV_sum\", \"VV_iqr\", \"VH_p2\", \"VH_p25\", \"VH_median\", \"VH_p75\", \"VH_p98\", \"VH_mean\", \"VH_sd\", \"VH_sum\", \"VH_iqr\", \"RVI_p2\", \"RVI_p25\", \"RVI_median\", \"RVI_p75\", \"RVI_p98\", \"RVI_mean\", \"RVI_sd\", \"RVI_sum\", \"RVI_iqr\", \"VHVVD_p2\", \"VHVVD_p25\", \"VHVVD_median\", \"VHVVD_p75\", \"VHVVD_p98\", \"VHVVD_mean\", \"VHVVD_sd\", \"VHVVD_sum\", \"VHVVD_iqr\", \"VHVVR_p2\", \"VHVVR_p25\", \"VHVVR_median\", \"VHVVR_p75\", \"VHVVR_p98\", \"VHVVR_mean\", \"VHVVR_sd\", \"VHVVR_sum\", \"VHVVR_iqr\"]}, \"process_id\": \"rename_labels\"}, \"resamplespatial1\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"loadcollection1\"}, \"method\": \"near\", \"projection\": 3035, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"resamplespatial2\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"loadcollection2\"}, \"method\": \"near\", \"projection\": 3035, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"resamplespatial3\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"sarbackscatter1\"}, \"method\": \"near\", \"projection\": 3035, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"resamplespatial4\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"reducedimension1\"}, \"method\": \"bilinear\", \"projection\": 3035, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"resamplespatial5\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"loadstac1\"}, \"method\": \"near\", \"projection\": 3035, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"sarbackscatter1\": {\"arguments\": {\"coefficient\": \"sigma0-ellipsoid\", \"contributing_area\": false, \"data\": {\"from_node\": \"loadcollection3\"}, \"elevation_model\": \"COPERNICUS_30\", \"ellipsoid_incidence_angle\": false, \"local_incidence_angle\": false, \"mask\": false, \"noise_removal\": true, \"options\": {\"debug\": false, \"elev_geoid\": \"/opt/openeo-vito-aux-data/egm96.tif\", \"implementation_version\": \"2\", \"otb_memory\": 1024, \"tile_size\": 256}}, \"process_id\": \"sar_backscatter\"}, \"saveresult1\": {\"arguments\": {\"data\": {\"from_node\": \"apply4\"}, \"format\": \"GTiff\", \"options\": {\"attach_gdalinfo_assets\": true, \"filename_prefix\": \"2025_05_08_14_02_18\", \"separate_asset_per_band\": true}}, \"process_id\": \"save_result\", \"result\": true}, \"toscldilationmask1\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial2\"}, \"erosion_kernel_size\": 3, \"kernel1_size\": 17, \"kernel2_size\": 77, \"mask1_values\": [2, 4, 5, 6, 7], \"mask2_values\": [3, 8, 9, 10, 11], \"scl_band_name\": \"SCL\"}, \"process_id\": \"to_scl_dilation_mask\"}}}, \"progress\": 100, \"status\": \"finished\", \"updated\": \"2025-05-08T12:14:10Z\", \"usage\": {\"cpu\": {\"unit\": \"cpu-seconds\", \"value\": 3027.304996423}, \"duration\": {\"unit\": \"seconds\", \"value\": 681}, \"input_pixel\": {\"unit\": \"mega-pixel\", \"value\": 223.8496618270874}, \"max_executor_memory\": {\"unit\": \"gb\", \"value\": 2.3003883361816406}, \"memory\": {\"unit\": \"mb-seconds\", \"value\": 22057681.00958807}, \"network_received\": {\"unit\": \"b\", \"value\": 51724936777}, \"orfeo_backscatter_input_pixels\": {\"unit\": \"count\", \"value\": 54525952}, \"sar_backscatter_soft_errors\": {\"unit\": \"fraction\", \"value\": 0}}}}</script>\n",
       "    </openeo-job>\n",
       "    "
      ],
      "text/plain": [
       "<BatchJob job_id='j-250508120220409fb9610ed8f0f4c475'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "filename_prefix = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "file_path = \"\" + filename_prefix\n",
    "\n",
    "#we pass the model url as context information within the UDF\n",
    "udf  = openeo.UDF.from_file(\n",
    "        getUDFpath('udf_catboost_inference.py'),\n",
    "        runtime = \"Python\",\n",
    "        version=\"3.11\",\n",
    "        context={\n",
    "            \"model_id\": \"EUNIS2021plus_EU_v1_2024_PAN\"\n",
    "                }\n",
    ")\n",
    "\n",
    "# Apply the UDF to the data cube.\n",
    "catboost_classification = data_cube.apply_dimension(\n",
    "    process=udf, dimension = \"bands\")\n",
    "\n",
    "# catboost_classification = catboost_classification.rename_labels(dimension=\"bands\",target=output_features)\n",
    "catboost_classification = catboost_classification.linear_scale_range(0,100, 0,100)\n",
    "\n",
    "\n",
    "#Save each band as a seperate tiff file\n",
    "save_result_options = {\n",
    "        \"filename_prefix\": filename_prefix,\n",
    "        \"attach_gdalinfo_assets\": True, \n",
    "    }\n",
    "\n",
    "save_result_options[\"separate_asset_per_band\"] = True\n",
    "result_datacube = catboost_classification.save_result(\n",
    "            format=\"GTiff\",\n",
    "            options = save_result_options)\n",
    "\n",
    "# Get current datetime\n",
    "file_path = \"test/\" \n",
    "\n",
    "# result_datacube = result_datacube.process(\n",
    "#     \"export_workspace\",\n",
    "#     arguments={\n",
    "#         \"data\": result_datacube,\n",
    "#         \"workspace\": \"esa-weed-workspace\",\n",
    "#         \"merge\": file_path,  # this determines the folder structure on the s3 bucket\n",
    "#     },\n",
    "# )\n",
    "\n",
    "#create and run the job\n",
    "job = connection.create_job(result_datacube,\n",
    "    additional=job_options,\n",
    ")\n",
    "\n",
    "job.start_and_wait()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
