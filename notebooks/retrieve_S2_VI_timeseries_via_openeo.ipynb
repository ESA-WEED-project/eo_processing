{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7066fd",
   "metadata": {},
   "source": [
    "## test to generate S2 VI time series data <br>\n",
    "\n",
    "we use the ts_datacube_extraction function but modify the collection data that we only get the Sentinel-2 data cube. <br>\n",
    "On that Sentinel-2 timeseries cube we will apply the Awsome-package to add the VI's to the S2 data cube.\n",
    "\n",
    "All data is scaled to Int16 with nodata value set to -32768! The data is extracted for 1 year and temporal resampled to 10-daily intervals -> 36 time stamps per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0aecb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T08:29:22.504307300Z",
     "start_time": "2023-07-17T08:29:22.504307300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUCHHORM\\Anaconda3\\envs\\extent\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import openeo\n",
    "from extentmapping.openeo.preprocessing import ts_datacube_extraction\n",
    "from extentmapping.config import get_job_options, get_collection_options, get_advanced_dataextraction_options\n",
    "from extentmapping.utils import laea20km_id_to_extent, reproj_bbox_to_ll\n",
    "from openeo.extra.spectral_indices import compute_and_rescale_indices\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68369278",
   "metadata": {},
   "source": [
    "### connect to the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67995fba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-17T08:29:54.478413300Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "#backend = 'terrascope'\n",
    "backend = 'development'    # for current tests\n",
    "\n",
    "# Make connection\n",
    "if backend == 'terrascope':\n",
    "    connection = openeo.connect(\"https://openeo.vito.be\").authenticate_oidc()\n",
    "elif backend == 'development':\n",
    "    connection = openeo.connect(\"https://openeo-dev.vito.be\").authenticate_oidc()\n",
    "else:\n",
    "    print('currently no specific connections to backends like creodias and sentinelhub are setup.')\n",
    "    print('use standard entry point')\n",
    "    connection = openeo.connect(\"https://openeo.cloud\").authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db1c73",
   "metadata": {},
   "source": [
    "### init the job, processing and collection option depending on provider and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37940a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_options = get_job_options(provider=backend, task='data_extraction')\n",
    "collection_options = get_collection_options(provider=backend)\n",
    "# reset S1, DEM and Agera5 to only get Sentinel2 data cube\n",
    "collection_options.update(METEO_collection=None, S1_collection=None, DEM_collection=None)\n",
    "processing_options = get_advanced_dataextraction_options(provider=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6b832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_options: {'driver-memory': '4G', 'driver-memoryOverhead': '4G', 'driver-cores': '2', 'executor-memory': '3G', 'executor-memoryOverhead': '2G', 'executor-cores': '2', 'max-executors': '50', 'soft-errors': 'true'}\n",
      "collection_options: {'S2_collection': 'SENTINEL2_L2A', 'METEO_collection': None, 'S1_collection': None, 'DEM_collection': None}\n",
      "processing_options: {'provider': 'development', 's1_orbitdirection': 'DESCENDING', 'target_crs': 3035, 'resolution': 10.0, 'time_interpolation': False, 'ts_interval': 'dekad', 'SLC_masking_algo': 'mask_scl_dilation'}\n"
     ]
    }
   ],
   "source": [
    "# just print for an overview\n",
    "print(f'job_options: {job_options}')\n",
    "print(f'collection_options: {collection_options}')\n",
    "print(f'processing_options: {processing_options}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7585e3b",
   "metadata": {},
   "source": [
    "### specify the space and time context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fe1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time context is given by start and end date\n",
    "start = '2020-01-01'\n",
    "end = '2021-01-01'   # the end is always exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f321f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the space context is defined as a bounding box dictionary with south,west,north,east and crs\n",
    "# we take as example the AOI of Daniele's test for habitat mapping\n",
    "AOI = {'east': 601000, 'south': 5699000, 'west': 600000, 'north': 5700000, 'crs': 'EPSG:32631'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a399dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area of AOI in km2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create area info for AOI\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "df = gpd.GeoDataFrame({\"id\":1,\"geometry\":[box(AOI['west'], AOI['south'], AOI['east'], AOI['north'])]})\n",
    "df.crs = AOI['crs']\n",
    "print(f'area of AOI in km2: {df.iloc[0].geometry.area/ 10**6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a2bd5",
   "metadata": {},
   "source": [
    "### run over the AOI and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d44521",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = 6\n",
    "\n",
    "# define the output folder root\n",
    "out_root = os.path.normpath(r'C:\\Users\\BUCHHORM\\OneDrive - VITO\\Documents\\Project_work\\PEOPLE-EA\\habitat_mapping\\VI_generation')\n",
    "out_root = os.path.join(out_root, f'test_v{str(test_num)}')\n",
    "os.makedirs(out_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the dictionary to specify the VIs and scaling ranges of input and output\n",
    "# NDMI == NDWI after Gao; NDWI == NDWI after McFeeter\n",
    "S2_vi_dict = {\n",
    "    \"collection\": {\n",
    "        \"input_range\": [0,10000],\n",
    "        \"output_range\": [0,1]\n",
    "    },\n",
    "    \"indices\": {\n",
    "        \"NDVI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"ATSAVI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"AVI\": {\n",
    "            \"input_range\": [0,1],\n",
    "            \"output_range\": [0,10000]\n",
    "        },\n",
    "        \"CIRE\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"EVI\": {\n",
    "            \"input_range\": [-10,10],\n",
    "            \"output_range\": [-20000,20000]\n",
    "        },\n",
    "        \"NIRv\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"SIPI\": {\n",
    "            \"input_range\": [-10,10],\n",
    "            \"output_range\": [-20000,20000]\n",
    "        },\n",
    "        \"NDMI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NDWI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NBRplus\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"BAIS2\": {\n",
    "            \"input_range\": [-1,6],\n",
    "            \"output_range\": [-1000,6000]\n",
    "        },\n",
    "        \"kNDVI\": {\n",
    "            \"input_range\": [0,1],\n",
    "            \"output_range\": [0,10000]\n",
    "        },\n",
    "        \"BLFEI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"MNDWI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NDVIMNDWI\": {\n",
    "            \"input_range\": [-2,2],\n",
    "            \"output_range\": [-20000,20000]\n",
    "        },\n",
    "        \"S2WI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"SAVI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"S2REP\": {\n",
    "            \"input_range\": [700,800],\n",
    "            \"output_range\": [7000,8000]\n",
    "        },\n",
    "        \"IRECI\": {\n",
    "            \"input_range\": [0,10],\n",
    "            \"output_range\": [0,10000]\n",
    "        },\n",
    "        \"NDGI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### due to issue with the awesome package implementation in openEo NO VI's with constants can be used\n",
    "## also the band definition for Sentinel2 is not correct in the openEO implementation (RE4 should be N2)\n",
    "S2_vi_dict = {\n",
    "    \"collection\": {\n",
    "        \"input_range\": [0,10000],\n",
    "        \"output_range\": [0,1]\n",
    "    },\n",
    "    \"indices\": {\n",
    "        \"NDVI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"AVI\": {\n",
    "            \"input_range\": [0,1],\n",
    "            \"output_range\": [0,10000]\n",
    "        },\n",
    "        \"CIRE\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NIRv\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NDMI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NDWI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"BLFEI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"MNDWI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"NDVIMNDWI\": {\n",
    "            \"input_range\": [-2,2],\n",
    "            \"output_range\": [-20000,20000]\n",
    "        },\n",
    "        \"S2WI\": {\n",
    "            \"input_range\": [-1,1],\n",
    "            \"output_range\": [-10000,10000]\n",
    "        },\n",
    "        \"S2REP\": {\n",
    "            \"input_range\": [700,800],\n",
    "            \"output_range\": [7000,8000]\n",
    "        },\n",
    "        \"IRECI\": {\n",
    "            \"input_range\": [0,10],\n",
    "            \"output_range\": [0,10000]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c402a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** processing AOI\n",
      "0:00:00 Job 'j-2311120a884e4280b72f207d00e4d9a5': send 'start'\n",
      "0:00:19 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:00:25 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:00:31 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:00:39 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:00:49 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:01:02 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:01:17 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:01:37 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:02:01 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:02:31 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:03:08 Job 'j-2311120a884e4280b72f207d00e4d9a5': queued (progress N/A)\n",
      "0:03:55 Job 'j-2311120a884e4280b72f207d00e4d9a5': running (progress N/A)\n",
      "0:04:53 Job 'j-2311120a884e4280b72f207d00e4d9a5': running (progress N/A)\n",
      "0:05:54 Job 'j-2311120a884e4280b72f207d00e4d9a5': running (progress N/A)\n",
      "0:06:54 Job 'j-2311120a884e4280b72f207d00e4d9a5': running (progress N/A)\n",
      "0:07:54 Job 'j-2311120a884e4280b72f207d00e4d9a5': error (progress N/A)\n",
      "Your batch job 'j-2311120a884e4280b72f207d00e4d9a5' failed. Error logs:\n",
      "[{'id': '[1699803534808, 342806]', 'time': '2023-11-12T15:38:54.808Z', 'level': 'error', 'message': 'Task 30 in stage 27.0 failed 4 times; aborting job'}, {'id': '[1699803534818, 343142]', 'time': '2023-11-12T15:38:54.818Z', 'level': 'error', 'message': 'Stage error: Job aborted due to stage failure: Task 30 in stage 27.0 failed 4 times, most recent failure: Lost task 30.3 in stage 27.0 (TID 368) (epod101.vgt.vito.be executor 11): java.lang.AssertionError: assertion failed: Band 1 cell type does not match, uint16ud65535 != int16\\n\\tat scala.Predef$.assert(Predef.scala:223)\\n\\tat geotrellis.raster.ArrayMultibandTile.<init>(ArrayMultibandTile.scala:100)\\n\\tat geotrellis.raster.ArrayMultibandTile$.apply(ArrayMultibandTile.scala:46)\\n\\tat geotrellis.raster.MultibandTile$.apply(MultibandTile.scala:37)\\n\\tat org.openeo.geotrellis.OpenEOProcesses.$anonfun$mapBandsGeneric$2(OpenEOProcesses.scala:487)\\n\\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\\n\\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\\n\\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:514)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\\n\\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\\n\\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\\n\\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4(CoGroupedRDD.scala:155)\\n\\tat org.apache.spark.rdd.CoGroupedRDD.$anonfun$compute$4$adapted(CoGroupedRDD.scala:154)\\n\\tat scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)\\n\\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:154)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat geotrellis.spark.ContextRDD.compute(ContextRDD.scala:36)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat geotrellis.spark.ContextRDD.compute(ContextRDD.scala:36)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat geotrellis.spark.ContextRDD.compute(ContextRDD.scala:36)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat geotrellis.spark.ContextRDD.compute(ContextRDD.scala:36)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\\n\\tat geotrellis.spark.ContextRDD.compute(ContextRDD.scala:36)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:377)\\n\\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1535)\\n\\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\\n\\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\\n\\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\\n\\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\n\\tat java.base/java.lang.Thread.run(Thread.java:829)\\n\\nDriver stacktrace:'}, {'id': '[1699803535213, 0]', 'time': '2023-11-12T15:38:55.213Z', 'level': 'error', 'message': 'Still have 1 requests outstanding when connection from epod086.vgt.vito.be/192.168.207.186:44281 is closed'}, {'id': '[1699803535215, 81866]', 'time': '2023-11-12T15:38:55.215Z', 'level': 'error', 'message': 'OpenEO batch job failed: Exception during Spark execution: assertion failed: Band 1 cell type does not match, uint16ud65535 != int16'}, {'id': '[1699803535233, 424]', 'time': '2023-11-12T15:38:55.233Z', 'level': 'error', 'message': 'Error communicating with MapOutputTracker'}, {'id': '[1699803605433, 10356075]', 'time': '2023-11-12T15:40:05.433Z', 'level': 'error', 'message': 'YARN application status reports error diagnostics: User application exited with status 1'}]\n",
      "Full logs can be inspected in an openEO (web) editor or with `connection.job('j-2311120a884e4280b72f207d00e4d9a5').logs()`.\n",
      "Batch job 'j-2311120a884e4280b72f207d00e4d9a5' didn't finish successfully. Status: error (after 0:07:54).\n"
     ]
    }
   ],
   "source": [
    "print(f'**** processing AOI')\n",
    "# define the job to get input data --> here only Sentinel-2 datacube\n",
    "S2_ts_cube = ts_datacube_extraction(connection,\n",
    "                                   AOI,\n",
    "                                   start,\n",
    "                                   end,\n",
    "                                   **collection_options,\n",
    "                                   **processing_options)\n",
    "# rescale S2 data cube into Int16\n",
    "S2_ts_cube = S2_ts_cube.linear_scale_range(-32767, 32767, -32767, 32767)\n",
    "\n",
    "\n",
    "# add the VI generation to the cube (later that comes in a warper function in openeo folder of extentmapping package])\n",
    "# warper should automatically reduce to S2 cube by altering the collection options for ts_datacube_extraction\n",
    "\n",
    "S2_vi_cube = compute_and_rescale_indices(datacube=S2_ts_cube, index_dict=S2_vi_dict, append=False)\n",
    "# force Int16\n",
    "S2_vi_cube = S2_vi_cube.linear_scale_range(-32767, 32767, -32767, 32767)\n",
    "\n",
    "\n",
    "S2_ts_cube_extented = S2_ts_cube.merge_cubes(S2_vi_cube)\n",
    "\n",
    "\n",
    "# run it\n",
    "try:\n",
    "    job = S2_ts_cube_extented.execute_batch(title=f'VI generation for AOI - test {str(test_num)}',\n",
    "                                  description='Generation of VI from S2 via OpenEO',\n",
    "                                  out_format='NetCDF',\n",
    "                                  job_options=job_options)\n",
    "\n",
    "    # Get the results and save to output file\n",
    "    results = job.get_results()\n",
    "\n",
    "    outputfile = os.path.join(out_root, f'S2_ref-and-VI_timeseries_openeo_AOI_test-v{str(test_num)}.nc')\n",
    "    results.download_file(outputfile)\n",
    "    # get metadata and job info\n",
    "    with open(outputfile.replace('.nc','.json'), \"w\") as outfile:\n",
    "        json.dump(results.get_metadata(),outfile)\n",
    "    with open(outputfile.replace('.nc','-job.json'), \"w\") as outfile:\n",
    "        json.dump(job.describe_job(),outfile)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and check the last processed file\n",
    "import xarray\n",
    "ts = xarray.load_dataset(outputfile)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extent",
   "language": "python",
   "name": "extent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
